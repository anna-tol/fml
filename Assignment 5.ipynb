{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentals of Machine Learning <br>\n",
    "Master Data-Driven Design <br>\n",
    "University of Applied Science Utrecht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words model and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-words is an algorithm that counts the occurance of words in a text. Since it only represents the frequency of each individual word, context is lost. Information regarding the order or structure is discarded. For example: words that belong together, such as 'New York' ('New' and 'York'), are seen as seperate words and countes seperately.\n",
    "\n",
    "The Naive Bayes classifier, on the other hand, is an algorithm that classifies features. The algorithm sees these feautures as seperate and independent. It is called naive because this is most often not the case. Using the Naive Bayes algorithm, we can predict whether a review is positive or neutral/negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "data = pd.read_csv('Assignment text mining - data clothing reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discarding all reviews other than dresses\n",
    "data = data.loc[(data['Class Name'] == 'Dresses')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping review text and rating + nice and clean renaming\n",
    "data = data[['Review Text', 'Rating']]\n",
    "data = data.rename(columns = {'Review Text': 'review', 'Rating': 'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data into neutral/negative and positive\n",
    "data['rating'] = data['rating'].map(\n",
    "    {0: 'neutral/negative', \n",
    "     1: 'neutral/negative',\n",
    "     2: 'neutral/negative',\n",
    "     3: 'neutral/negative',\n",
    "     4: 'positive',\n",
    "     5: 'positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the nothing\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>neutral/negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>neutral/negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I love this dress. i usually get an xs but it ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm 5\"5' and 125 lbs. i ordered the s petite t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review            rating\n",
       "1  Love this dress!  it's sooo pretty.  i happene...          positive\n",
       "2  I had such high hopes for this dress and reall...  neutral/negative\n",
       "5  I love tracy reese dresses, but this one is no...  neutral/negative\n",
       "8  I love this dress. i usually get an xs but it ...          positive\n",
       "9  I'm 5\"5' and 125 lbs. i ordered the s petite t...          positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to unicode\n",
    "text = data['review'].values.astype('U') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object with English stopwords and fit our text with the model\n",
    "vect = CountVectorizer(stop_words = 'english')\n",
    "vect = vect.fit(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features\n",
    "doc_feat = vect.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (2, 8)\t1\n",
      "  (20, 38)\t1\n",
      "  (21, 4)\t1\n",
      "  (21, 45)\t1\n",
      "  (22, 12)\t1\n",
      "  (25, 40)\t1\n",
      "  (34, 12)\t2\n",
      "  (38, 31)\t1\n"
     ]
    }
   ],
   "source": [
    "# print to show we got something\n",
    "print(doc_feat[0 : 50, 0 : 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document-feature matrix as x and rating as y\n",
    "x = doc_feat\n",
    "y = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test and training set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "nb = nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_test_p = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8508676789587852"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the accuracy of those predictions\n",
    "nb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is 85%, which is quite okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral/negative pred</th>\n",
       "      <th>positive pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral/negative</th>\n",
       "      <td>301</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>107</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  neutral/negative pred  positive pred\n",
       "neutral/negative                    301            168\n",
       "positive                            107           1268"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a confusion matrix\n",
    "conf_matr = confusion_matrix(y_test, y_test_p)\n",
    "pd.DataFrame(conf_matr, index = ['neutral/negative', 'positive'], \n",
    "             columns = ['neutral/negative pred', 'positive pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "neutral/negative       0.74      0.64      0.69       469\n",
      "        positive       0.88      0.92      0.90      1375\n",
      "\n",
      "        accuracy                           0.85      1844\n",
      "       macro avg       0.81      0.78      0.79      1844\n",
      "    weighted avg       0.85      0.85      0.85      1844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "print(classification_report(y_test, y_test_p, nb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral/negative: really, small, love, look, fit, just, fabric, size, like, dress\n",
      "positive: flattering, fabric, just, great, like, wear, fit, love, size, dress\n"
     ]
    }
   ],
   "source": [
    "# get all features\n",
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "# get top 10\n",
    "top = 10\n",
    "\n",
    "for i, class_label in enumerate(nb.classes_):\n",
    "    \n",
    "    # find top features (numbers)\n",
    "    results = np.argsort(nb.feature_log_prob_[i])[-top:]\n",
    "    \n",
    "    # translate numbers to corresponding words\n",
    "    print(\"%s: %s\" % (class_label, ', '.join(feature_names[j] for j in results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't find these very informative since they overlap quite a lot, but ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you cancel out the overlap:\n",
    "* really, small, look\n",
    "* flattering, great, wear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
